#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸŒ§ï¸ CARGA INICIAL COMPLETA - Dados PluviomÃ©tricos

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ PROPÃ“SITO DESTE SCRIPT:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Este script foi criado para fazer a CARGA INICIAL COMPLETA de todos os dados
pluviomÃ©tricos histÃ³ricos do banco alertadb (origem) para o banco alertadb_cor
(destino).

Ã‰ o PRIMEIRO PASSO necessÃ¡rio antes de usar o sincronizar_pluviometricos_novos.py.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ O QUE ESTE SCRIPT FAZ:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Busca TODOS os dados desde 1997-01-01 atÃ© a data atual
âœ… Cria a tabela pluviometricos se ela nÃ£o existir
âœ… Processa dados em lotes de 10.000 registros para otimizar memÃ³ria
âœ… Usa DISTINCT ON para garantir apenas um registro por (dia, estacao_id)
âœ… MantÃ©m o registro mais recente (maior ID) quando hÃ¡ duplicatas
âœ… Garante que os dados no destino sejam EXATAMENTE como no banco alertadb
âœ… Mostra progresso detalhado durante a carga
âœ… Exibe estatÃ­sticas finais (total de registros, perÃ­odo dos dados)
âœ… Diagnostica duplicatas no banco origem antes da carga

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ QUANDO USAR ESTE SCRIPT:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Primeira vez que vocÃª estÃ¡ configurando o sistema
âœ… Quando a tabela pluviometricos estÃ¡ vazia
âœ… ApÃ³s limpar/resetar a tabela de destino
âœ… Para recarregar todos os dados histÃ³ricos

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ COMO USAR:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Configure o arquivo .env com as credenciais dos bancos
2. Execute: python carregar_pluviometricos_historicos.py
3. Aguarde a conclusÃ£o (pode levar vÃ¡rios minutos dependendo do volume)
4. ApÃ³s concluir, execute o sincronizar_pluviometricos_novos.py para manter atualizado

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”’ PROTEÃ‡Ã•ES IMPLEMENTADAS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Chave primÃ¡ria composta (dia, estacao_id) garante unicidade
âœ… DISTINCT ON garante apenas um registro por (dia, estacao_id) do banco origem
âœ… MantÃ©m o registro mais recente (maior ID) quando hÃ¡ duplicatas
âœ… Garante que os dados no destino sejam EXATAMENTE como no banco alertadb
âœ… ON CONFLICT DO UPDATE atualiza dados existentes com valores corretos
âœ… Corrige automaticamente dados incorretos se jÃ¡ existirem na tabela
âœ… Processamento em lotes evita sobrecarga de memÃ³ria
âœ… ValidaÃ§Ã£o de conexÃµes antes de iniciar
âœ… DiagnÃ³stico de duplicatas antes da carga
âœ… Tratamento de erros com mensagens claras

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ CONFIGURAÃ‡ÃƒO:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Todas as configuraÃ§Ãµes devem estar no arquivo .env na raiz do projeto.

VariÃ¡veis obrigatÃ³rias:
- DB_ORIGEM_HOST, DB_ORIGEM_NAME, DB_ORIGEM_USER, DB_ORIGEM_PASSWORD
- DB_DESTINO_HOST, DB_DESTINO_NAME, DB_DESTINO_USER, DB_DESTINO_PASSWORD

VariÃ¡veis opcionais:
- DB_ORIGEM_SSLMODE (padrÃ£o: disable)
- DB_DESTINO_PORT (padrÃ£o: 5432)
"""

# ğŸ”§ Importar bibliotecas necessÃ¡rias
import psycopg2
from psycopg2 import errors as psycopg2_errors
from psycopg2.extras import execute_values
import os
import re
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Carregar variÃ¡veis de ambiente (busca .env na raiz do projeto)
import sys
from pathlib import Path
# Obter diretÃ³rio raiz do projeto (2 nÃ­veis acima deste arquivo)
project_root = Path(__file__).parent.parent.parent
load_dotenv(dotenv_path=project_root / '.env')

def extrair_timezone_offset(dt):
    """
    Extrai o offset de timezone de um datetime aware.
    
    Args:
        dt: datetime objeto com timezone
    
    Returns:
        str: offset no formato '-03:00' ou None se nÃ£o tiver timezone
    """
    if not isinstance(dt, datetime) or dt.tzinfo is None:
        return None
    
    # Obter offset total em segundos
    offset_seconds = dt.tzinfo.utcoffset(dt).total_seconds()
    
    # Converter para horas e minutos
    horas = int(offset_seconds // 3600)
    minutos = int((offset_seconds % 3600) // 60)
    
    # Formatar como '-03:00' ou '+03:00'
    sinal = '-' if horas < 0 else '+'
    return f"{sinal}{abs(horas):02d}:{abs(minutos):02d}"

def preparar_timestamp_para_insercao(dt):
    """
    Prepara um timestamp para inserÃ§Ã£o no PostgreSQL mantendo o timezone correto.
    
    IMPORTANTE: Quando o banco origem retorna '2025-11-28 11:40:00.000 -0300',
    precisamos inserir no banco destino como '2025-11-28 11:40:00.000 -0300'
    para que o PostgreSQL interprete corretamente e armazene sem diferenÃ§a de horas.
    
    Args:
        dt: datetime objeto (aware ou naive)
    
    Returns:
        str: timestamp formatado para inserÃ§Ã£o no PostgreSQL
    """
    if not isinstance(dt, datetime):
        return str(dt)
    
    # Se tem timezone, manter o timezone na string
    if dt.tzinfo is not None:
        offset = extrair_timezone_offset(dt)
        if offset:
            # Formatar como '2025-11-28 11:40:00.000 -03:00'
            timestamp_str = dt.strftime('%Y-%m-%d %H:%M:%S')
            if dt.microsecond:
                timestamp_str += f".{dt.microsecond:06d}"[:7]  # Limitar a 3 dÃ­gitos
            return f"{timestamp_str} {offset}"
    
    # Se nÃ£o tem timezone, retornar como estÃ¡ (assumindo que jÃ¡ estÃ¡ no timezone correto)
    timestamp_str = dt.strftime('%Y-%m-%d %H:%M:%S')
    if dt.microsecond:
        timestamp_str += f".{dt.microsecond:06d}"[:7]
    return timestamp_str

def garantir_datetime_com_timezone(valor):
    """
    Garante que o valor seja um objeto datetime mantendo o timezone original.
    IMPORTANTE: Preserva o timezone original (-02:00 para horÃ¡rio de verÃ£o ou -03:00 para horÃ¡rio padrÃ£o).
    
    Args:
        valor: datetime, string ou outro tipo
    
    Returns:
        datetime: datetime com timezone preservado (ou naive se nÃ£o tinha timezone)
    """
    resultado = None
    
    if isinstance(valor, datetime):
        # Se jÃ¡ Ã© datetime, manter como estÃ¡ (com ou sem timezone)
        # IMPORTANTE: Preserva tanto -02:00 quanto -03:00
        resultado = valor
    elif isinstance(valor, str):
        try:
            # Tentar parse mantendo timezone se presente
            # Formatos esperados:
            # - "2025-11-28 11:40:00.000 -0300" (horÃ¡rio padrÃ£o)
            # - "2019-02-16 23:45:00.000 -0200" (horÃ¡rio de verÃ£o)
            # - "2019-02-16 23:45:00.000 -0200 -03:00" ou "-02:00"
            
            # Tentar usar fromisoformat primeiro (preserva timezone automaticamente)
            try:
                # fromisoformat funciona com formato ISO que tem 'T' e timezone
                valor_iso = valor.replace(' ', 'T', 1)
                resultado = datetime.fromisoformat(valor_iso)
            except:
                # Se falhar, fazer parse manual preservando timezone
                # Extrair timezone se presente (formato -0300 ou -03:00 ou -0200 ou -02:00)
                match_tz = re.search(r'\s*([+-])(\d{2}):?(\d{2})$', valor)
                if match_tz:
                    sinal = match_tz.group(1)  # '+' ou '-'
                    horas_tz = int(match_tz.group(2))
                    minutos_tz = int(match_tz.group(3))
                    
                    # Calcular offset total em minutos
                    offset_total_minutos = horas_tz * 60 + minutos_tz
                    if sinal == '-':
                        offset_total_minutos = -offset_total_minutos
                    
                    # Remover timezone da string para fazer parse do datetime
                    valor_sem_tz = re.sub(r'\s*[+-]\d{2}:?\d{2}$', '', valor).strip()
                    
                    # Parse do datetime (sem timezone)
                    formatos = [
                        '%Y-%m-%d %H:%M:%S.%f',
                        '%Y-%m-%d %H:%M:%S',
                        '%Y-%m-%dT%H:%M:%S.%f',
                        '%Y-%m-%dT%H:%M:%S',
                    ]
                    
                    dt_naive = None
                    for fmt in formatos:
                        try:
                            dt_naive = datetime.strptime(valor_sem_tz, fmt)
                            break
                        except ValueError:
                            continue
                    
                    if dt_naive:
                        # Criar timezone com offset preservado (-02:00 ou -03:00)
                        from datetime import timezone
                        tz = timezone(timedelta(minutes=offset_total_minutos))
                        resultado = dt_naive.replace(tzinfo=tz)
                else:
                    # Sem timezone na string, fazer parse normal
                    valor_limpo = valor.strip()
                    formatos = [
                        '%Y-%m-%d %H:%M:%S.%f',
                        '%Y-%m-%d %H:%M:%S',
                        '%Y-%m-%dT%H:%M:%S.%f',
                        '%Y-%m-%dT%H:%M:%S',
                    ]
                    
                    for fmt in formatos:
                        try:
                            resultado = datetime.strptime(valor_limpo, fmt)
                            break
                        except ValueError:
                            continue
        except Exception as e:
            resultado = datetime.now() - timedelta(seconds=300)
    else:
        try:
            if hasattr(valor, 'year') and hasattr(valor, 'month') and hasattr(valor, 'day'):
                resultado = datetime.combine(valor, datetime.min.time())
            else:
                resultado = datetime.now() - timedelta(seconds=300)
        except:
            resultado = datetime.now() - timedelta(seconds=300)
    
    return resultado if resultado else datetime.now() - timedelta(seconds=300)

def obter_variavel(nome, obrigatoria=True):
    """ObtÃ©m variÃ¡vel de ambiente, lanÃ§a erro se obrigatÃ³ria e nÃ£o encontrada."""
    valor = os.getenv(nome)
    if obrigatoria and not valor:
        raise ValueError(f"âŒ VariÃ¡vel de ambiente obrigatÃ³ria nÃ£o encontrada: {nome}")
    return valor

def carregar_configuracoes():
    """Carrega todas as configuraÃ§Ãµes do arquivo .env."""
    try:
        # âš™ï¸ ConfiguraÃ§Ãµes de conexÃ£o ORIGEM
        origem = {
            'host': obter_variavel('DB_ORIGEM_HOST'),
            'dbname': obter_variavel('DB_ORIGEM_NAME'),
            'user': obter_variavel('DB_ORIGEM_USER'),
            'password': obter_variavel('DB_ORIGEM_PASSWORD'),
            'sslmode': obter_variavel('DB_ORIGEM_SSLMODE', obrigatoria=False) or 'disable'
        }

        # âš™ï¸ ConfiguraÃ§Ãµes de conexÃ£o DESTINO
        destino = {
            'host': obter_variavel('DB_DESTINO_HOST'),
            'port': obter_variavel('DB_DESTINO_PORT', obrigatoria=False) or '5432',
            'dbname': obter_variavel('DB_DESTINO_NAME'),
            'user': obter_variavel('DB_DESTINO_USER'),
            'password': obter_variavel('DB_DESTINO_PASSWORD'),
            'connect_timeout': 10  # Timeout de 10 segundos para conexÃ£o
        }
        
        return origem, destino
    
    except ValueError as e:
        print("=" * 60)
        print("âŒ ERRO DE CONFIGURAÃ‡ÃƒO")
        print("=" * 60)
        print(str(e))
        print("\nğŸ“ Verifique se o arquivo .env existe e contÃ©m todas as variÃ¡veis necessÃ¡rias")
        print("=" * 60)
        raise

# Carregar configuraÃ§Ãµes
ORIGEM, DESTINO = carregar_configuracoes()

# ğŸ§± Query para buscar TODOS os dados (sem filtro de data)
def query_todos_dados():
    """Retorna query para buscar TODOS os dados disponÃ­veis no banco.
    
    Usa DISTINCT ON para garantir apenas um registro por (dia, estacao_id),
    mantendo o registro com o maior ID (mais recente), que Ã© exatamente como
    estÃ¡ no banco alertadb.
    
    IMPORTANTE: A ordem do ORDER BY deve corresponder Ã  ordem do DISTINCT ON,
    e depois ordenar por id DESC para pegar o registro mais recente.
    """
    return """
SELECT DISTINCT ON (el."horaLeitura", el.estacao_id)
    el."horaLeitura" AS "Dia",
    elc.m05,
    elc.m10,
    elc.m15,
    elc.h01,
    elc.h04,
    elc.h24,
    elc.h96,
    ee.nome AS "Estacao",
    el.estacao_id
FROM public.estacoes_leitura AS el
JOIN public.estacoes_leiturachuva AS elc
    ON elc.leitura_id = el.id
JOIN public.estacoes_estacao AS ee
    ON ee.id = el.estacao_id
ORDER BY el."horaLeitura" ASC, el.estacao_id ASC, el.id DESC;
"""

# ğŸ§± Query para buscar dados desde uma data especÃ­fica
def query_dados_desde_data(data_inicial):
    """Retorna query para buscar dados desde uma data especÃ­fica.
    
    Usa DISTINCT ON para garantir apenas um registro por (dia, estacao_id),
    mantendo o registro com o maior ID (mais recente), que Ã© exatamente como
    estÃ¡ no banco alertadb.
    
    IMPORTANTE: A ordem do ORDER BY deve corresponder Ã  ordem do DISTINCT ON,
    e depois ordenar por id DESC para pegar o registro mais recente.
    """
    return f"""
SELECT DISTINCT ON (el."horaLeitura", el.estacao_id)
    el."horaLeitura" AS "Dia",
    elc.m05,
    elc.m10,
    elc.m15,
    elc.h01,
    elc.h04,
    elc.h24,
    elc.h96,
    ee.nome AS "Estacao",
    el.estacao_id
FROM public.estacoes_leitura AS el
JOIN public.estacoes_leiturachuva AS elc
    ON elc.leitura_id = el.id
JOIN public.estacoes_estacao AS ee
    ON ee.id = el.estacao_id
WHERE el."horaLeitura" >= '{data_inicial}'::timestamp
ORDER BY el."horaLeitura" ASC, el.estacao_id ASC, el.id DESC;
"""

def testar_conexoes():
    """Testa as conexÃµes com ambos os bancos antes de sincronizar."""
    print("=" * 60)
    print("TESTE DE CONEXOES")
    print("=" * 60)
    
    try:
        conn_origem = psycopg2.connect(**ORIGEM)
        print("   âœ… CONEXÃƒO ORIGEM: SUCESSO!")
        conn_origem.close()
        
        conn_destino = psycopg2.connect(**DESTINO)
        print("   âœ… CONEXÃƒO DESTINO: SUCESSO!")
        conn_destino.close()
        return True
        
    except Exception as e:
        print(f"   âŒ ERRO: {e}")
        return False

def criar_tabela_pluviometricos():
    """Cria a tabela pluviometricos no banco de destino se ela nÃ£o existir."""
    conn_destino = None
    cur_destino = None
    
    try:
        conn_destino = psycopg2.connect(**DESTINO)
        cur_destino = conn_destino.cursor()
        
        create_table_sql = '''
        CREATE TABLE IF NOT EXISTS pluviometricos (
            dia TIMESTAMP NOT NULL,
            m05 NUMERIC,
            m10 NUMERIC,
            m15 NUMERIC,
            h01 NUMERIC,
            h04 NUMERIC,
            h24 NUMERIC,
            h96 NUMERIC,
            estacao VARCHAR(255),
            estacao_id INTEGER,
            PRIMARY KEY (dia, estacao_id)
        );
        '''
        
        cur_destino.execute(create_table_sql)
        conn_destino.commit()
        print('âœ… Tabela pluviometricos criada/verificada com sucesso!')
        
    except Exception as e:
        print(f'âŒ Erro ao criar tabela: {e}')
        if conn_destino:
            conn_destino.rollback()
    finally:
        if cur_destino:
            cur_destino.close()
        if conn_destino:
            conn_destino.close()

def verificar_tabela_vazia():
    """Verifica se a tabela pluviometricos estÃ¡ vazia.
    
    Usa EXISTS com LIMIT 1 para ser muito mais rÃ¡pido que COUNT(*) em tabelas grandes.
    """
    conn_destino = None
    cur_destino = None
    
    try:
        conn_destino = psycopg2.connect(**DESTINO)
        cur_destino = conn_destino.cursor()
        
        # Usar EXISTS Ã© muito mais rÃ¡pido que COUNT(*) em tabelas grandes
        # Adiciona timeout de 5 segundos para a query
        cur_destino.execute("SET statement_timeout = '5s';")
        cur_destino.execute("SELECT EXISTS(SELECT 1 FROM pluviometricos LIMIT 1);")
        resultado = cur_destino.fetchone()
        
        # EXISTS retorna True se hÃ¡ pelo menos um registro, False se vazia
        return not resultado[0] if resultado else True
            
    except psycopg2_errors.QueryCanceled:
        print('âš ï¸ Timeout ao verificar tabela. Assumindo que a tabela nÃ£o estÃ¡ vazia.')
        return False
    except Exception as e:
        print(f'âš ï¸ Erro ao verificar tabela: {e}')
        return True
    finally:
        if cur_destino:
            cur_destino.close()
        if conn_destino:
            conn_destino.close()

def validar_amostra_dados(conn_origem, conn_destino, cur_origem, cur_destino, quantidade=10):
    """
    Valida uma amostra de dados inseridos comparando com o banco origem.
    
    Args:
        conn_origem: ConexÃ£o com banco origem
        conn_destino: ConexÃ£o com banco destino
        cur_origem: Cursor do banco origem
        cur_destino: Cursor do banco destino
        quantidade: Quantidade de registros para validar
    
    Returns:
        bool: True se todos os registros validados estÃ£o corretos, False caso contrÃ¡rio
    """
    try:
        # Buscar alguns registros aleatÃ³rios do banco destino
        cur_destino.execute(f"""
            SELECT dia, m05, m10, m15, h01, h04, h24, h96, estacao, estacao_id
            FROM pluviometricos
            ORDER BY RANDOM()
            LIMIT {quantidade};
        """)
        registros_destino = cur_destino.fetchall()
        
        if not registros_destino:
            return True  # Se nÃ£o hÃ¡ registros, nÃ£o hÃ¡ o que validar
        
        divergencias = 0
        
        for registro_destino in registros_destino:
            dia_dest, m05_dest, m10_dest, m15_dest, h01_dest, h04_dest, h24_dest, h96_dest, estacao_dest, est_id_dest = registro_destino
            
            # Buscar registro correspondente no banco origem
            query_origem = """
            SELECT DISTINCT ON (el."horaLeitura", el.estacao_id)
                el."horaLeitura" AS "Dia",
                elc.m05,
                elc.m10,
                elc.m15,
                elc.h01,
                elc.h04,
                elc.h24,
                elc.h96,
                ee.nome AS "Estacao",
                el.estacao_id
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id
            WHERE el."horaLeitura" = %s::timestamp
              AND el.estacao_id = %s
            ORDER BY el."horaLeitura" ASC, el.estacao_id ASC, el.id DESC
            LIMIT 1;
            """
            
            cur_origem.execute(query_origem, (dia_dest, est_id_dest))
            registro_origem = cur_origem.fetchone()
            
            if registro_origem:
                dia_orig, m05_orig, m10_orig, m15_orig, h01_orig, h04_orig, h24_orig, h96_orig, estacao_orig, est_id_orig = registro_origem
                
                # Comparar valores (ignorar diferenÃ§as de timezone no timestamp)
                valores_origem = (m05_orig, m10_orig, m15_orig, h01_orig, h04_orig, h24_orig, h96_orig)
                valores_destino = (m05_dest, m10_dest, m15_dest, h01_dest, h04_dest, h24_dest, h96_dest)
                
                if valores_origem != valores_destino:
                    divergencias += 1
        
        return divergencias == 0
        
    except Exception as e:
        print(f'   âš ï¸  Erro na validaÃ§Ã£o: {e}')
        return False

def diagnosticar_banco_origem():
    """Diagnostica o banco de origem para verificar dados disponÃ­veis."""
    conn_origem = None
    cur_origem = None
    
    try:
        print("\n" + "=" * 70)
        print("ğŸ” DIAGNÃ“STICO DO BANCO DE ORIGEM")
        print("=" * 70)
        
        conn_origem = psycopg2.connect(**ORIGEM)
        cur_origem = conn_origem.cursor()
        
        # 1. Verificar total de registros em estacoes_leitura
        print("\nğŸ“Š Verificando tabelas...")
        cur_origem.execute("SELECT COUNT(*) FROM public.estacoes_leitura;")
        total_leitura = cur_origem.fetchone()[0]
        print(f"   â€¢ Total de registros em estacoes_leitura: {total_leitura:,}")
        
        # 2. Verificar total de registros em estacoes_leiturachuva
        cur_origem.execute("SELECT COUNT(*) FROM public.estacoes_leiturachuva;")
        total_chuva = cur_origem.fetchone()[0]
        print(f"   â€¢ Total de registros em estacoes_leiturachuva: {total_chuva:,}")
        
        # 3. Verificar data mÃ­nima e mÃ¡xima em estacoes_leitura
        cur_origem.execute("""
            SELECT 
                MIN("horaLeitura") as data_min,
                MAX("horaLeitura") as data_max
            FROM public.estacoes_leitura;
        """)
        datas_leitura = cur_origem.fetchone()
        data_min_leitura = datas_leitura[0] if datas_leitura[0] else None
        data_max_leitura = datas_leitura[1] if datas_leitura[1] else None
        print(f"   â€¢ Data mÃ­nima em estacoes_leitura: {data_min_leitura}")
        print(f"   â€¢ Data mÃ¡xima em estacoes_leitura: {data_max_leitura}")
        
        # 4. Verificar quantos registros tÃªm JOIN vÃ¡lido
        cur_origem.execute("""
            SELECT COUNT(*)
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id;
        """)
        total_com_join = cur_origem.fetchone()[0]
        print(f"   â€¢ Total de registros com JOIN vÃ¡lido: {total_com_join:,}")
        
        # 5. Verificar data mÃ­nima e mÃ¡xima dos dados com JOIN vÃ¡lido
        cur_origem.execute("""
            SELECT 
                MIN(el."horaLeitura") as data_min,
                MAX(el."horaLeitura") as data_max
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id;
        """)
        datas_join = cur_origem.fetchone()
        data_min_join = datas_join[0] if datas_join[0] else None
        data_max_join = datas_join[1] if datas_join[1] else None
        print(f"   â€¢ Data mÃ­nima com JOIN vÃ¡lido: {data_min_join}")
        print(f"   â€¢ Data mÃ¡xima com JOIN vÃ¡lido: {data_max_join}")
        
        # 6. Verificar dados por dÃ©cada/ano
        print("\nğŸ“… DistribuiÃ§Ã£o de dados por ano:")
        cur_origem.execute("""
            SELECT 
                EXTRACT(YEAR FROM el."horaLeitura") as ano,
                COUNT(*) as total
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id
            GROUP BY EXTRACT(YEAR FROM el."horaLeitura")
            ORDER BY ano;
        """)
        distribuicao_anos = cur_origem.fetchall()
        for ano, total in distribuicao_anos:
            print(f"   â€¢ {int(ano)}: {total:,} registros")
        
        # 7. Verificar se hÃ¡ dados em janeiro de 1997
        print("\nğŸ” Verificando dados especÃ­ficos em janeiro de 1997:")
        cur_origem.execute("""
            SELECT COUNT(*)
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id
            WHERE el."horaLeitura" >= '1997-01-01'::timestamp
              AND el."horaLeitura" < '1997-02-01'::timestamp;
        """)
        total_jan_1997 = cur_origem.fetchone()[0]
        print(f"   â€¢ Registros em janeiro/1997: {total_jan_1997:,}")
        
        if total_jan_1997 == 0:
            print("   âš ï¸  ATENÃ‡ÃƒO: NÃ£o hÃ¡ dados em janeiro de 1997!")
            print("   ğŸ’¡ Isso confirma que a data inicial de 1997-01-01 pode estar incorreta.")
        
        # 8. Verificar duplicatas (mÃºltiplos registros com mesmo dia e estacao_id)
        print("\nğŸ” Verificando duplicatas (mesmo dia + estacao_id):")
        cur_origem.execute("""
            SELECT 
                el."horaLeitura",
                el.estacao_id,
                COUNT(*) as total
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id
            GROUP BY el."horaLeitura", el.estacao_id
            HAVING COUNT(*) > 1
            ORDER BY COUNT(*) DESC
            LIMIT 10;
        """)
        duplicatas = cur_origem.fetchall()
        
        # Contar total de combinaÃ§Ãµes duplicadas
        cur_origem.execute("""
            SELECT COUNT(*)
            FROM (
                SELECT el."horaLeitura", el.estacao_id
                FROM public.estacoes_leitura AS el
                JOIN public.estacoes_leiturachuva AS elc
                    ON elc.leitura_id = el.id
                JOIN public.estacoes_estacao AS ee
                    ON ee.id = el.estacao_id
                GROUP BY el."horaLeitura", el.estacao_id
                HAVING COUNT(*) > 1
            ) AS dups;
        """)
        total_duplicatas = cur_origem.fetchone()[0]
        
        if duplicatas:
            print(f"   âš ï¸  ATENÃ‡ÃƒO: Encontradas {total_duplicatas:,} combinaÃ§Ãµes (dia, estacao_id) com mÃºltiplos registros!")
            print(f"   â€¢ Exemplos de duplicatas (mostrando atÃ© 10 primeiras):")
            for hora_leitura, estacao_id, total in duplicatas[:5]:
                print(f"      - {hora_leitura} | estacao_id={estacao_id}: {total} registros")
            print(f"   ğŸ’¡ A query serÃ¡ ajustada para usar DISTINCT ON e manter apenas o registro mais recente.")
        else:
            print(f"   âœ… Nenhuma duplicata encontrada.")
        
        print("=" * 70)
        
        return {
            'total_leitura': total_leitura,
            'total_chuva': total_chuva,
            'total_com_join': total_com_join,
            'data_min': data_min_join,
            'data_max': data_max_join,
            'total_jan_1997': total_jan_1997,
            'tem_duplicatas': total_duplicatas > 0,
            'total_duplicatas': total_duplicatas
        }
        
    except Exception as e:
        print(f'\nâŒ Erro no diagnÃ³stico: {e}')
        import traceback
        traceback.print_exc()
        return None
    finally:
        if cur_origem:
            cur_origem.close()
        if conn_origem:
            conn_origem.close()

def carregar_dados_completos(usar_data_inicial=None):
    """Carrega todos os dados disponÃ­veis no banco."""
    conn_origem = None
    cur_origem = None
    conn_destino = None
    cur_destino = None
    
    timestamp_atual = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    try:
        # Verificar se jÃ¡ existem dados
        if not verificar_tabela_vazia():
            resposta = input("\nâš ï¸  A tabela jÃ¡ contÃ©m dados. Deseja continuar mesmo assim? (s/N): ")
            if resposta.lower() != 's':
                print("âŒ OperaÃ§Ã£o cancelada pelo usuÃ¡rio.")
                return 0
        
        # Executar diagnÃ³stico primeiro
        diagnostico = diagnosticar_banco_origem()
        
        if not diagnostico:
            print("\nâŒ NÃ£o foi possÃ­vel executar o diagnÃ³stico. Continuando mesmo assim...")
        else:
            if diagnostico['total_com_join'] == 0:
                print("\nâŒ ERRO: NÃ£o hÃ¡ dados disponÃ­veis no banco de origem!")
                print("   Verifique se as tabelas estÃ£o populadas corretamente.")
                return 0
            
            # Perguntar se deseja usar todos os dados ou filtrar por data
            if usar_data_inicial is None:
                print(f"\nğŸ“‹ Dados disponÃ­veis:")
                print(f"   â€¢ Data mÃ­nima: {diagnostico['data_min']}")
                print(f"   â€¢ Data mÃ¡xima: {diagnostico['data_max']}")
                print(f"   â€¢ Total de registros: {diagnostico['total_com_join']:,}")
                
                resposta = input("\nâ“ Deseja buscar TODOS os dados disponÃ­veis? (S/n): ")
                if resposta.lower() == 'n':
                    data_input = input("   Digite a data inicial (formato: YYYY-MM-DD) ou pressione Enter para usar a data mÃ­nima: ")
                    if data_input.strip():
                        usar_data_inicial = data_input.strip()
                    else:
                        usar_data_inicial = str(diagnostico['data_min'])[:10] if diagnostico['data_min'] else None
                else:
                    usar_data_inicial = None
        
        # Conectar ao banco origem
        conn_origem = psycopg2.connect(**ORIGEM)
        cur_origem = conn_origem.cursor()
        
        # Executar query apropriada
        if usar_data_inicial:
            print(f"\nğŸ”„ Iniciando carga completa desde {usar_data_inicial}...")
            query = query_dados_desde_data(usar_data_inicial)
        else:
            print(f"\nğŸ”„ Iniciando carga completa de TODOS os dados disponÃ­veis...")
            query = query_todos_dados()
        
        print(f"   Isso pode levar vÃ¡rios minutos dependendo do volume de dados...")
        print(f"   Por favor, aguarde...\n")
        
        cur_origem.execute(query)
        
        # Processar em lotes para evitar problemas de memÃ³ria
        TAMANHO_LOTE = 10000
        total_inseridos = 0
        lote_numero = 1
        
        # Conectar ao banco destino
        conn_destino = psycopg2.connect(**DESTINO)
        cur_destino = conn_destino.cursor()

        # Usar ON CONFLICT DO UPDATE para garantir que os dados sejam sempre atualizados
        # com os valores corretos do banco origem, mesmo se jÃ¡ existirem dados incorretos
        # A query jÃ¡ garante apenas um registro por (dia, estacao_id) usando DISTINCT ON
        # com ORDER BY id DESC (mais recente)
        # IMPORTANTE: O psycopg2 vai converter automaticamente timestamps com timezone
        # para o timezone do servidor antes de armazenar. Para evitar diferenÃ§a de 3 horas,
        # precisamos garantir que o timestamp seja inserido com o timezone correto (-03:00)
        # e o PostgreSQL vai converter para o timezone do servidor mantendo o valor local.
        insert_sql = '''
        INSERT INTO pluviometricos
        (dia, m05, m10, m15, h01, h04, h24, h96, estacao, estacao_id)
        VALUES %s
        ON CONFLICT (dia, estacao_id) 
        DO UPDATE SET
            m05 = EXCLUDED.m05,
            m10 = EXCLUDED.m10,
            m15 = EXCLUDED.m15,
            h01 = EXCLUDED.h01,
            h04 = EXCLUDED.h04,
            h24 = EXCLUDED.h24,
            h96 = EXCLUDED.h96,
            estacao = EXCLUDED.estacao;
        '''
        
        # Configurar timezone do banco destino para 'America/Sao_Paulo' durante a inserÃ§Ã£o
        # Isso garante que timestamps com timezone sejam convertidos corretamente
        cur_destino.execute("SET timezone = 'America/Sao_Paulo';")
        
        # Processar dados em lotes
        print("ğŸ“¦ Processando dados em lotes de 10.000 registros...")
        print("   ğŸ’¡ A query usa DISTINCT ON para garantir apenas um registro por (dia, estacao_id),")
        print("      mantendo o registro mais recente (maior ID), exatamente como no banco alertadb.\n")
        
        primeira_data = None
        ultima_data = None
        
        while True:
            dados = cur_origem.fetchmany(TAMANHO_LOTE)
            
            if not dados:
                break
            
            # IMPORTANTE: Preparar timestamps mantendo timezone para inserÃ§Ã£o correta
            # Formato dos dados: (dia, m05, m10, m15, h01, h04, h24, h96, estacao, estacao_id)
            # Quando o banco origem retorna timestamps com timezone:
            # - '2025-11-28 11:40:00.000 -0300' (horÃ¡rio padrÃ£o)
            # - '2019-02-16 23:45:00.000 -0200' (horÃ¡rio de verÃ£o)
            # Precisamos preservar o timezone original para que o PostgreSQL converta corretamente
            dados_ajustados = []
            for registro in dados:
                dia_original = registro[0]
                
                # Se jÃ¡ Ã© datetime com timezone, manter como estÃ¡ (preserva -02:00 ou -03:00)
                if isinstance(dia_original, datetime) and dia_original.tzinfo:
                    dia_ajustado = dia_original
                elif isinstance(dia_original, datetime):
                    # Se Ã© datetime sem timezone, converter para string e tentar parse novamente
                    # para detectar se hÃ¡ timezone na representaÃ§Ã£o original
                    dia_ajustado = garantir_datetime_com_timezone(str(dia_original))
                    # Se ainda nÃ£o tem timezone apÃ³s conversÃ£o, assumir -03:00 (padrÃ£o BrasÃ­lia)
                    if dia_ajustado.tzinfo is None:
                        from datetime import timezone
                        tz_brasilia = timezone(timedelta(hours=-3))
                        dia_ajustado = dia_original.replace(tzinfo=tz_brasilia)
                else:
                    # Se Ã© string ou outro tipo, converter mantendo timezone original (-02:00 ou -03:00)
                    dia_ajustado = garantir_datetime_com_timezone(dia_original)
                    # Se nÃ£o tem timezone apÃ³s conversÃ£o, adicionar -03:00 (padrÃ£o BrasÃ­lia)
                    if dia_ajustado.tzinfo is None:
                        from datetime import timezone
                        tz_brasilia = timezone(timedelta(hours=-3))
                        dia_ajustado = dia_ajustado.replace(tzinfo=tz_brasilia)
                
                # Criar nova tupla com o timestamp ajustado (com timezone)
                registro_ajustado = (dia_ajustado,) + registro[1:]
                dados_ajustados.append(registro_ajustado)
            
            # Log de debug para primeiro lote (apenas para verificaÃ§Ã£o)
            if lote_numero == 1 and dados_ajustados:
                primeiro_registro = dados_ajustados[0]
                dia_original = dados[0][0]
                print(f'   ğŸ” Exemplo de timestamp processado:')
                print(f'      Original: {dia_original} (tipo: {type(dia_original)})')
                print(f'      Processado: {primeiro_registro[0]} (tipo: {type(primeiro_registro[0])})')
                if hasattr(primeiro_registro[0], 'tzinfo') and primeiro_registro[0].tzinfo:
                    offset = primeiro_registro[0].tzinfo.utcoffset(primeiro_registro[0])
                    print(f'      Timezone offset: {offset}')
            
            # Capturar primeira e Ãºltima data do lote atual (apÃ³s ajuste)
            data_inicio_lote = dados_ajustados[0][0] if dados_ajustados else None
            data_fim_lote = dados_ajustados[-1][0] if dados_ajustados else None
            
            # Capturar primeira e Ãºltima data geral
            if primeira_data is None:
                primeira_data = data_inicio_lote
            ultima_data = data_fim_lote
            
            execute_values(cur_destino, insert_sql, dados_ajustados)
            conn_destino.commit()
            
            total_inseridos += len(dados)
            print(f'   ğŸ“¦ Lote {lote_numero}: {len(dados):,} registros processados (Total acumulado: {total_inseridos:,})')
            if data_inicio_lote and data_fim_lote:
                print(f'      ğŸ“… PerÃ­odo deste lote: {data_inicio_lote} atÃ© {data_fim_lote}')
            lote_numero += 1
        
        if total_inseridos == 0:
            print(f'\n   âš ï¸  Nenhum dado encontrado para inserir.')
            print(f'   ğŸ’¡ Verifique o diagnÃ³stico acima para entender o problema.')
            return 0
        
        # Obter estatÃ­sticas finais
        cur_destino.execute("SELECT COUNT(*) FROM pluviometricos;")
        total_tabela = cur_destino.fetchone()[0]
        
        cur_destino.execute("SELECT MIN(dia), MAX(dia) FROM pluviometricos;")
        datas = cur_destino.fetchone()
        data_min = datas[0] if datas[0] else None
        data_max = datas[1] if datas[1] else None
        
        print("\n" + "=" * 70)
        print("âœ… CARGA INICIAL COMPLETA FINALIZADA!")
        print("=" * 70)
        print(f"ğŸ“Š Total de registros inseridos nesta execuÃ§Ã£o: {total_inseridos:,}")
        print(f"ğŸ“Š Total de registros na tabela: {total_tabela:,}")
        if data_min and data_max:
            print(f"ğŸ“… PerÃ­odo dos dados na tabela: {data_min} atÃ© {data_max}")
        if primeira_data and ultima_data:
            print(f"ğŸ“… PerÃ­odo dos dados inseridos: {primeira_data} atÃ© {ultima_data}")
        print(f"â° ConcluÃ­do em: {timestamp_atual}")
        print("=" * 70)
        
        # Verificar se hÃ¡ lacunas
        if data_min and data_max:
            print("\nğŸ” Verificando distribuiÃ§Ã£o de dados por ano na tabela destino:")
            cur_destino.execute("""
                SELECT 
                    EXTRACT(YEAR FROM dia) as ano,
                    COUNT(*) as total
                FROM pluviometricos
                GROUP BY EXTRACT(YEAR FROM dia)
                ORDER BY ano;
            """)
            distribuicao_destino = cur_destino.fetchall()
            for ano, total in distribuicao_destino:
                print(f"   â€¢ {int(ano)}: {total:,} registros")
        
        # Validar alguns registros para garantir que os dados estÃ£o corretos
        print("\nğŸ” Validando dados inseridos...")
        validacao_ok = validar_amostra_dados(conn_origem, conn_destino, cur_origem, cur_destino)
        
        if validacao_ok:
            print("   âœ… ValidaÃ§Ã£o: Dados inseridos correspondem ao banco origem!")
        else:
            print("   âš ï¸  ATENÃ‡ÃƒO: Foram encontradas divergÃªncias na validaÃ§Ã£o!")
            print("   ğŸ’¡ Execute o script novamente para corrigir os dados.")
        
        print("\nğŸ’¡ PRÃ“XIMO PASSO:")
        print("   Execute o script 'sincronizar_pluviometricos_novos.py' para manter")
        print("   os dados atualizados em tempo real a cada 5 minutos.\n")
        
        return total_inseridos

    except Exception as e:
        print(f'\nâŒ Erro na carga: {e}')
        return 0

    finally:
        if cur_origem:
            cur_origem.close()
        if conn_origem:
            conn_origem.close()
        if cur_destino:
            cur_destino.close()
        if conn_destino:
            conn_destino.close()

def main():
    """FunÃ§Ã£o principal que executa a carga inicial completa."""
    print("=" * 70)
    print("ğŸŒ§ï¸ CARGA INICIAL COMPLETA - DADOS PLUVIOMÃ‰TRICOS")
    print("=" * 70)
    print()
    print("ğŸ¯ PROPÃ“SITO:")
    print("   Este script faz a CARGA INICIAL COMPLETA de todos os dados")
    print("   pluviomÃ©tricos disponÃ­veis no banco de origem.")
    print()
    print("ğŸ“‹ O QUE SERÃ FEITO:")
    print("   âœ… Diagnosticar o banco de origem para verificar dados disponÃ­veis")
    print("   âœ… Buscar TODOS os dados histÃ³ricos disponÃ­veis (sem filtro fixo)")
    print("   âœ… Criar a tabela pluviometricos se nÃ£o existir")
    print("   âœ… Processar em lotes de 10.000 registros")
    print("   âœ… Mostrar progresso e estatÃ­sticas detalhadas durante a carga")
    print()
    print("âš ï¸  IMPORTANTE:")
    print("   - Execute APENAS UMA VEZ para fazer a carga inicial")
    print("   - ApÃ³s concluir, use sincronizar_pluviometricos_novos.py para manter atualizado")
    print("   - O processo pode levar vÃ¡rios minutos dependendo do volume de dados")
    print("=" * 70)
    
    # Testar conexÃµes
    if not testar_conexoes():
        print("\nâŒ Falha nos testes de conexÃ£o. Abortando...")
        return

    # Criar/verificar tabela
    print("\nğŸ“‹ Verificando estrutura do banco de dados...")
    criar_tabela_pluviometricos()

    # Executar carga completa
    carregar_dados_completos()

if __name__ == "__main__":
    main()

