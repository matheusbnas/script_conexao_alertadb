#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üåßÔ∏è CARGA INICIAL COMPLETA - Dados Pluviom√©tricos

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üéØ PROP√ìSITO DESTE SCRIPT:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Este script foi criado para fazer a CARGA INICIAL COMPLETA de todos os dados
pluviom√©tricos hist√≥ricos do banco alertadb (origem) para o banco carioca_digital
(destino).

√â o PRIMEIRO PASSO necess√°rio antes de usar o sincronizar_pluviometricos_novos.py.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìã O QUE ESTE SCRIPT FAZ:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚úÖ Busca TODOS os dados desde 1997-01-01 at√© a data atual
‚úÖ Cria a tabela pluviometricos se ela n√£o existir
‚úÖ Processa dados em lotes de 10.000 registros para otimizar mem√≥ria
‚úÖ Usa DISTINCT ON para garantir apenas um registro por (dia, estacao_id)
‚úÖ Mant√©m o registro mais recente (maior ID) quando h√° duplicatas
‚úÖ Garante que os dados no destino sejam EXATAMENTE como no banco alertadb
‚úÖ Mostra progresso detalhado durante a carga
‚úÖ Exibe estat√≠sticas finais (total de registros, per√≠odo dos dados)
‚úÖ Diagnostica duplicatas no banco origem antes da carga

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ö†Ô∏è QUANDO USAR ESTE SCRIPT:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚úÖ Primeira vez que voc√™ est√° configurando o sistema
‚úÖ Quando a tabela pluviometricos est√° vazia
‚úÖ Ap√≥s limpar/resetar a tabela de destino
‚úÖ Para recarregar todos os dados hist√≥ricos

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üöÄ COMO USAR:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. Configure o arquivo .env com as credenciais dos bancos
2. Execute: python carregar_pluviometricos_historicos.py
3. Aguarde a conclus√£o (pode levar v√°rios minutos dependendo do volume)
4. Ap√≥s concluir, execute o sincronizar_pluviometricos_novos.py para manter atualizado

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üîí PROTE√á√ïES IMPLEMENTADAS:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚úÖ Chave prim√°ria composta (dia, estacao_id) garante unicidade
‚úÖ DISTINCT ON garante apenas um registro por (dia, estacao_id) do banco origem
‚úÖ Mant√©m o registro mais recente (maior ID) quando h√° duplicatas
‚úÖ Garante que os dados no destino sejam EXATAMENTE como no banco alertadb
‚úÖ ON CONFLICT DO NOTHING previne duplicatas se reexecutar
‚úÖ Processamento em lotes evita sobrecarga de mem√≥ria
‚úÖ Valida√ß√£o de conex√µes antes de iniciar
‚úÖ Diagn√≥stico de duplicatas antes da carga
‚úÖ Tratamento de erros com mensagens claras

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìã CONFIGURA√á√ÉO:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Todas as configura√ß√µes devem estar no arquivo .env na raiz do projeto.

Vari√°veis obrigat√≥rias:
- DB_ORIGEM_HOST, DB_ORIGEM_NAME, DB_ORIGEM_USER, DB_ORIGEM_PASSWORD
- DB_DESTINO_HOST, DB_DESTINO_NAME, DB_DESTINO_USER, DB_DESTINO_PASSWORD

Vari√°veis opcionais:
- DB_ORIGEM_SSLMODE (padr√£o: disable)
- DB_DESTINO_PORT (padr√£o: 5432)
"""

# üîß Importar bibliotecas necess√°rias
import psycopg2
from psycopg2.extras import execute_values
import os
import re
from datetime import datetime
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente (busca .env na raiz do projeto)
import sys
from pathlib import Path
# Obter diret√≥rio raiz do projeto (2 n√≠veis acima deste arquivo)
project_root = Path(__file__).parent.parent
load_dotenv(dotenv_path=project_root / '.env')

def obter_variavel(nome, obrigatoria=True):
    """Obt√©m vari√°vel de ambiente, lan√ßa erro se obrigat√≥ria e n√£o encontrada."""
    valor = os.getenv(nome)
    if obrigatoria and not valor:
        raise ValueError(f"‚ùå Vari√°vel de ambiente obrigat√≥ria n√£o encontrada: {nome}")
    return valor

def carregar_configuracoes():
    """Carrega todas as configura√ß√µes do arquivo .env."""
    try:
        # ‚öôÔ∏è Configura√ß√µes de conex√£o ORIGEM
        origem = {
            'host': obter_variavel('DB_ORIGEM_HOST'),
            'dbname': obter_variavel('DB_ORIGEM_NAME'),
            'user': obter_variavel('DB_ORIGEM_USER'),
            'password': obter_variavel('DB_ORIGEM_PASSWORD'),
            'sslmode': obter_variavel('DB_ORIGEM_SSLMODE', obrigatoria=False) or 'disable'
        }

        # ‚öôÔ∏è Configura√ß√µes de conex√£o DESTINO
        destino = {
            'host': obter_variavel('DB_DESTINO_HOST'),
            'port': obter_variavel('DB_DESTINO_PORT', obrigatoria=False) or '5432',
            'dbname': obter_variavel('DB_DESTINO_NAME'),
            'user': obter_variavel('DB_DESTINO_USER'),
            'password': obter_variavel('DB_DESTINO_PASSWORD')
        }
        
        return origem, destino
    
    except ValueError as e:
        print("=" * 60)
        print("‚ùå ERRO DE CONFIGURA√á√ÉO")
        print("=" * 60)
        print(str(e))
        print("\nüìù Verifique se o arquivo .env existe e cont√©m todas as vari√°veis necess√°rias")
        print("=" * 60)
        raise

# Carregar configura√ß√µes
ORIGEM, DESTINO = carregar_configuracoes()

# üß± Query para buscar TODOS os dados (sem filtro de data)
def query_todos_dados():
    """Retorna query para buscar TODOS os dados dispon√≠veis no banco.
    
    Usa DISTINCT ON para garantir apenas um registro por (dia, estacao_id),
    mantendo o registro com o maior ID (mais recente), que √© exatamente como
    est√° no banco alertadb.
    """
    return """
SELECT DISTINCT ON (el."horaLeitura", el.estacao_id)
    el."horaLeitura" AS "Dia",
    elc.m05,
    elc.m10,
    elc.m15,
    elc.h01,
    elc.h04,
    elc.h24,
    elc.h96,
    ee.nome AS "Estacao",
    el.estacao_id
FROM public.estacoes_leitura AS el
JOIN public.estacoes_leiturachuva AS elc
    ON elc.leitura_id = el.id
JOIN public.estacoes_estacao AS ee
    ON ee.id = el.estacao_id
ORDER BY el."horaLeitura" ASC, el.estacao_id ASC, el.id DESC;
"""

# üß± Query para buscar dados desde uma data espec√≠fica
def query_dados_desde_data(data_inicial):
    """Retorna query para buscar dados desde uma data espec√≠fica.
    
    Usa DISTINCT ON para garantir apenas um registro por (dia, estacao_id),
    mantendo o registro com o maior ID (mais recente), que √© exatamente como
    est√° no banco alertadb.
    """
    return f"""
SELECT DISTINCT ON (el."horaLeitura", el.estacao_id)
    el."horaLeitura" AS "Dia",
    elc.m05,
    elc.m10,
    elc.m15,
    elc.h01,
    elc.h04,
    elc.h24,
    elc.h96,
    ee.nome AS "Estacao",
    el.estacao_id
FROM public.estacoes_leitura AS el
JOIN public.estacoes_leiturachuva AS elc
    ON elc.leitura_id = el.id
JOIN public.estacoes_estacao AS ee
    ON ee.id = el.estacao_id
WHERE el."horaLeitura" >= '{data_inicial}'::timestamp
ORDER BY el."horaLeitura" ASC, el.estacao_id ASC, el.id DESC;
"""

def testar_conexoes():
    """Testa as conex√µes com ambos os bancos antes de sincronizar."""
    print("=" * 60)
    print("TESTE DE CONEXOES")
    print("=" * 60)
    
    try:
        conn_origem = psycopg2.connect(**ORIGEM)
        print("   ‚úÖ CONEX√ÉO ORIGEM: SUCESSO!")
        conn_origem.close()
        
        conn_destino = psycopg2.connect(**DESTINO)
        print("   ‚úÖ CONEX√ÉO DESTINO: SUCESSO!")
        conn_destino.close()
        return True
        
    except Exception as e:
        print(f"   ‚ùå ERRO: {e}")
        return False

def criar_tabela_pluviometricos():
    """Cria a tabela pluviometricos no banco de destino se ela n√£o existir."""
    conn_destino = None
    cur_destino = None
    
    try:
        conn_destino = psycopg2.connect(**DESTINO)
        cur_destino = conn_destino.cursor()
        
        create_table_sql = '''
        CREATE TABLE IF NOT EXISTS pluviometricos (
            dia TIMESTAMP NOT NULL,
            m05 NUMERIC,
            m10 NUMERIC,
            m15 NUMERIC,
            h01 NUMERIC,
            h04 NUMERIC,
            h24 NUMERIC,
            h96 NUMERIC,
            estacao VARCHAR(255),
            estacao_id INTEGER,
            PRIMARY KEY (dia, estacao_id)
        );
        '''
        
        cur_destino.execute(create_table_sql)
        conn_destino.commit()
        print('‚úÖ Tabela pluviometricos criada/verificada com sucesso!')
        
    except Exception as e:
        print(f'‚ùå Erro ao criar tabela: {e}')
        if conn_destino:
            conn_destino.rollback()
    finally:
        if cur_destino:
            cur_destino.close()
        if conn_destino:
            conn_destino.close()

def verificar_tabela_vazia():
    """Verifica se a tabela pluviometricos est√° vazia."""
    conn_destino = None
    cur_destino = None
    
    try:
        conn_destino = psycopg2.connect(**DESTINO)
        cur_destino = conn_destino.cursor()
        
        cur_destino.execute("SELECT COUNT(*) FROM pluviometricos;")
        resultado = cur_destino.fetchone()
        
        return resultado[0] == 0 if resultado else True
            
    except Exception as e:
        print(f'‚ö†Ô∏è Erro ao verificar tabela: {e}')
        return True
    finally:
        if cur_destino:
            cur_destino.close()
        if conn_destino:
            conn_destino.close()

def diagnosticar_banco_origem():
    """Diagnostica o banco de origem para verificar dados dispon√≠veis."""
    conn_origem = None
    cur_origem = None
    
    try:
        print("\n" + "=" * 70)
        print("üîç DIAGN√ìSTICO DO BANCO DE ORIGEM")
        print("=" * 70)
        
        conn_origem = psycopg2.connect(**ORIGEM)
        cur_origem = conn_origem.cursor()
        
        # 1. Verificar total de registros em estacoes_leitura
        print("\nüìä Verificando tabelas...")
        cur_origem.execute("SELECT COUNT(*) FROM public.estacoes_leitura;")
        total_leitura = cur_origem.fetchone()[0]
        print(f"   ‚Ä¢ Total de registros em estacoes_leitura: {total_leitura:,}")
        
        # 2. Verificar total de registros em estacoes_leiturachuva
        cur_origem.execute("SELECT COUNT(*) FROM public.estacoes_leiturachuva;")
        total_chuva = cur_origem.fetchone()[0]
        print(f"   ‚Ä¢ Total de registros em estacoes_leiturachuva: {total_chuva:,}")
        
        # 3. Verificar data m√≠nima e m√°xima em estacoes_leitura
        cur_origem.execute("""
            SELECT 
                MIN("horaLeitura") as data_min,
                MAX("horaLeitura") as data_max
            FROM public.estacoes_leitura;
        """)
        datas_leitura = cur_origem.fetchone()
        data_min_leitura = datas_leitura[0] if datas_leitura[0] else None
        data_max_leitura = datas_leitura[1] if datas_leitura[1] else None
        print(f"   ‚Ä¢ Data m√≠nima em estacoes_leitura: {data_min_leitura}")
        print(f"   ‚Ä¢ Data m√°xima em estacoes_leitura: {data_max_leitura}")
        
        # 4. Verificar quantos registros t√™m JOIN v√°lido
        cur_origem.execute("""
            SELECT COUNT(*)
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id;
        """)
        total_com_join = cur_origem.fetchone()[0]
        print(f"   ‚Ä¢ Total de registros com JOIN v√°lido: {total_com_join:,}")
        
        # 5. Verificar data m√≠nima e m√°xima dos dados com JOIN v√°lido
        cur_origem.execute("""
            SELECT 
                MIN(el."horaLeitura") as data_min,
                MAX(el."horaLeitura") as data_max
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id;
        """)
        datas_join = cur_origem.fetchone()
        data_min_join = datas_join[0] if datas_join[0] else None
        data_max_join = datas_join[1] if datas_join[1] else None
        print(f"   ‚Ä¢ Data m√≠nima com JOIN v√°lido: {data_min_join}")
        print(f"   ‚Ä¢ Data m√°xima com JOIN v√°lido: {data_max_join}")
        
        # 6. Verificar dados por d√©cada/ano
        print("\nüìÖ Distribui√ß√£o de dados por ano:")
        cur_origem.execute("""
            SELECT 
                EXTRACT(YEAR FROM el."horaLeitura") as ano,
                COUNT(*) as total
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id
            GROUP BY EXTRACT(YEAR FROM el."horaLeitura")
            ORDER BY ano;
        """)
        distribuicao_anos = cur_origem.fetchall()
        for ano, total in distribuicao_anos:
            print(f"   ‚Ä¢ {int(ano)}: {total:,} registros")
        
        # 7. Verificar se h√° dados em janeiro de 1997
        print("\nüîé Verificando dados espec√≠ficos em janeiro de 1997:")
        cur_origem.execute("""
            SELECT COUNT(*)
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id
            WHERE el."horaLeitura" >= '1997-01-01'::timestamp
              AND el."horaLeitura" < '1997-02-01'::timestamp;
        """)
        total_jan_1997 = cur_origem.fetchone()[0]
        print(f"   ‚Ä¢ Registros em janeiro/1997: {total_jan_1997:,}")
        
        if total_jan_1997 == 0:
            print("   ‚ö†Ô∏è  ATEN√á√ÉO: N√£o h√° dados em janeiro de 1997!")
            print("   üí° Isso confirma que a data inicial de 1997-01-01 pode estar incorreta.")
        
        # 8. Verificar duplicatas (m√∫ltiplos registros com mesmo dia e estacao_id)
        print("\nüîç Verificando duplicatas (mesmo dia + estacao_id):")
        cur_origem.execute("""
            SELECT 
                el."horaLeitura",
                el.estacao_id,
                COUNT(*) as total
            FROM public.estacoes_leitura AS el
            JOIN public.estacoes_leiturachuva AS elc
                ON elc.leitura_id = el.id
            JOIN public.estacoes_estacao AS ee
                ON ee.id = el.estacao_id
            GROUP BY el."horaLeitura", el.estacao_id
            HAVING COUNT(*) > 1
            ORDER BY COUNT(*) DESC
            LIMIT 10;
        """)
        duplicatas = cur_origem.fetchall()
        
        # Contar total de combina√ß√µes duplicadas
        cur_origem.execute("""
            SELECT COUNT(*)
            FROM (
                SELECT el."horaLeitura", el.estacao_id
                FROM public.estacoes_leitura AS el
                JOIN public.estacoes_leiturachuva AS elc
                    ON elc.leitura_id = el.id
                JOIN public.estacoes_estacao AS ee
                    ON ee.id = el.estacao_id
                GROUP BY el."horaLeitura", el.estacao_id
                HAVING COUNT(*) > 1
            ) AS dups;
        """)
        total_duplicatas = cur_origem.fetchone()[0]
        
        if duplicatas:
            print(f"   ‚ö†Ô∏è  ATEN√á√ÉO: Encontradas {total_duplicatas:,} combina√ß√µes (dia, estacao_id) com m√∫ltiplos registros!")
            print(f"   ‚Ä¢ Exemplos de duplicatas (mostrando at√© 10 primeiras):")
            for hora_leitura, estacao_id, total in duplicatas[:5]:
                print(f"      - {hora_leitura} | estacao_id={estacao_id}: {total} registros")
            print(f"   üí° A query ser√° ajustada para usar DISTINCT ON e manter apenas o registro mais recente.")
        else:
            print(f"   ‚úÖ Nenhuma duplicata encontrada.")
        
        print("=" * 70)
        
        return {
            'total_leitura': total_leitura,
            'total_chuva': total_chuva,
            'total_com_join': total_com_join,
            'data_min': data_min_join,
            'data_max': data_max_join,
            'total_jan_1997': total_jan_1997,
            'tem_duplicatas': total_duplicatas > 0,
            'total_duplicatas': total_duplicatas
        }
        
    except Exception as e:
        print(f'\n‚ùå Erro no diagn√≥stico: {e}')
        import traceback
        traceback.print_exc()
        return None
    finally:
        if cur_origem:
            cur_origem.close()
        if conn_origem:
            conn_origem.close()

def carregar_dados_completos(usar_data_inicial=None):
    """Carrega todos os dados dispon√≠veis no banco."""
    conn_origem = None
    cur_origem = None
    conn_destino = None
    cur_destino = None
    
    timestamp_atual = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    try:
        # Verificar se j√° existem dados
        if not verificar_tabela_vazia():
            resposta = input("\n‚ö†Ô∏è  A tabela j√° cont√©m dados. Deseja continuar mesmo assim? (s/N): ")
            if resposta.lower() != 's':
                print("‚ùå Opera√ß√£o cancelada pelo usu√°rio.")
                return 0
        
        # Executar diagn√≥stico primeiro
        diagnostico = diagnosticar_banco_origem()
        
        if not diagnostico:
            print("\n‚ùå N√£o foi poss√≠vel executar o diagn√≥stico. Continuando mesmo assim...")
        else:
            if diagnostico['total_com_join'] == 0:
                print("\n‚ùå ERRO: N√£o h√° dados dispon√≠veis no banco de origem!")
                print("   Verifique se as tabelas est√£o populadas corretamente.")
                return 0
            
            # Perguntar se deseja usar todos os dados ou filtrar por data
            if usar_data_inicial is None:
                print(f"\nüìã Dados dispon√≠veis:")
                print(f"   ‚Ä¢ Data m√≠nima: {diagnostico['data_min']}")
                print(f"   ‚Ä¢ Data m√°xima: {diagnostico['data_max']}")
                print(f"   ‚Ä¢ Total de registros: {diagnostico['total_com_join']:,}")
                
                resposta = input("\n‚ùì Deseja buscar TODOS os dados dispon√≠veis? (S/n): ")
                if resposta.lower() == 'n':
                    data_input = input("   Digite a data inicial (formato: YYYY-MM-DD) ou pressione Enter para usar a data m√≠nima: ")
                    if data_input.strip():
                        usar_data_inicial = data_input.strip()
                    else:
                        usar_data_inicial = str(diagnostico['data_min'])[:10] if diagnostico['data_min'] else None
                else:
                    usar_data_inicial = None
        
        # Conectar ao banco origem
        conn_origem = psycopg2.connect(**ORIGEM)
        cur_origem = conn_origem.cursor()
        
        # Executar query apropriada
        if usar_data_inicial:
            print(f"\nüîÑ Iniciando carga completa desde {usar_data_inicial}...")
            query = query_dados_desde_data(usar_data_inicial)
        else:
            print(f"\nüîÑ Iniciando carga completa de TODOS os dados dispon√≠veis...")
            query = query_todos_dados()
        
        print(f"   Isso pode levar v√°rios minutos dependendo do volume de dados...")
        print(f"   Por favor, aguarde...\n")
        
        cur_origem.execute(query)
        
        # Processar em lotes para evitar problemas de mem√≥ria
        TAMANHO_LOTE = 10000
        total_inseridos = 0
        lote_numero = 1
        
        # Conectar ao banco destino
        conn_destino = psycopg2.connect(**DESTINO)
        cur_destino = conn_destino.cursor()

        # Usar ON CONFLICT DO NOTHING pois a query j√° garante apenas um registro por (dia, estacao_id)
        # usando DISTINCT ON com ORDER BY id DESC (mais recente)
        insert_sql = '''
        INSERT INTO pluviometricos
        (dia, m05, m10, m15, h01, h04, h24, h96, estacao, estacao_id)
        VALUES %s
        ON CONFLICT (dia, estacao_id) DO NOTHING;
        '''
        
        # Processar dados em lotes
        print("üì¶ Processando dados em lotes de 10.000 registros...")
        print("   üí° A query usa DISTINCT ON para garantir apenas um registro por (dia, estacao_id),")
        print("      mantendo o registro mais recente (maior ID), exatamente como no banco alertadb.\n")
        
        primeira_data = None
        ultima_data = None
        
        while True:
            dados = cur_origem.fetchmany(TAMANHO_LOTE)
            
            if not dados:
                break
            
            # Capturar primeira e √∫ltima data do lote atual
            data_inicio_lote = dados[0][0] if dados else None
            data_fim_lote = dados[-1][0] if dados else None
            
            # Capturar primeira e √∫ltima data geral
            if primeira_data is None:
                primeira_data = data_inicio_lote
            ultima_data = data_fim_lote
            
            execute_values(cur_destino, insert_sql, dados)
            conn_destino.commit()
            
            total_inseridos += len(dados)
            print(f'   üì¶ Lote {lote_numero}: {len(dados):,} registros processados (Total acumulado: {total_inseridos:,})')
            if data_inicio_lote and data_fim_lote:
                print(f'      üìÖ Per√≠odo deste lote: {data_inicio_lote} at√© {data_fim_lote}')
            lote_numero += 1
        
        if total_inseridos == 0:
            print(f'\n   ‚ö†Ô∏è  Nenhum dado encontrado para inserir.')
            print(f'   üí° Verifique o diagn√≥stico acima para entender o problema.')
            return 0
        
        # Obter estat√≠sticas finais
        cur_destino.execute("SELECT COUNT(*) FROM pluviometricos;")
        total_tabela = cur_destino.fetchone()[0]
        
        cur_destino.execute("SELECT MIN(dia), MAX(dia) FROM pluviometricos;")
        datas = cur_destino.fetchone()
        data_min = datas[0] if datas[0] else None
        data_max = datas[1] if datas[1] else None
        
        print("\n" + "=" * 70)
        print("‚úÖ CARGA INICIAL COMPLETA FINALIZADA!")
        print("=" * 70)
        print(f"üìä Total de registros inseridos nesta execu√ß√£o: {total_inseridos:,}")
        print(f"üìä Total de registros na tabela: {total_tabela:,}")
        if data_min and data_max:
            print(f"üìÖ Per√≠odo dos dados na tabela: {data_min} at√© {data_max}")
        if primeira_data and ultima_data:
            print(f"üìÖ Per√≠odo dos dados inseridos: {primeira_data} at√© {ultima_data}")
        print(f"‚è∞ Conclu√≠do em: {timestamp_atual}")
        print("=" * 70)
        
        # Verificar se h√° lacunas
        if data_min and data_max:
            print("\nüîç Verificando distribui√ß√£o de dados por ano na tabela destino:")
            cur_destino.execute("""
                SELECT 
                    EXTRACT(YEAR FROM dia) as ano,
                    COUNT(*) as total
                FROM pluviometricos
                GROUP BY EXTRACT(YEAR FROM dia)
                ORDER BY ano;
            """)
            distribuicao_destino = cur_destino.fetchall()
            for ano, total in distribuicao_destino:
                print(f"   ‚Ä¢ {int(ano)}: {total:,} registros")
        
        print("\nüí° PR√ìXIMO PASSO:")
        print("   Execute o script 'sincronizar_pluviometricos_novos.py' para manter")
        print("   os dados atualizados em tempo real a cada 5 minutos.\n")
        
        return total_inseridos

    except Exception as e:
        print(f'\n‚ùå Erro na carga: {e}')
        return 0

    finally:
        if cur_origem:
            cur_origem.close()
        if conn_origem:
            conn_origem.close()
        if cur_destino:
            cur_destino.close()
        if conn_destino:
            conn_destino.close()

def main():
    """Fun√ß√£o principal que executa a carga inicial completa."""
    print("=" * 70)
    print("üåßÔ∏è CARGA INICIAL COMPLETA - DADOS PLUVIOM√âTRICOS")
    print("=" * 70)
    print()
    print("üéØ PROP√ìSITO:")
    print("   Este script faz a CARGA INICIAL COMPLETA de todos os dados")
    print("   pluviom√©tricos dispon√≠veis no banco de origem.")
    print()
    print("üìã O QUE SER√Å FEITO:")
    print("   ‚úÖ Diagnosticar o banco de origem para verificar dados dispon√≠veis")
    print("   ‚úÖ Buscar TODOS os dados hist√≥ricos dispon√≠veis (sem filtro fixo)")
    print("   ‚úÖ Criar a tabela pluviometricos se n√£o existir")
    print("   ‚úÖ Processar em lotes de 10.000 registros")
    print("   ‚úÖ Mostrar progresso e estat√≠sticas detalhadas durante a carga")
    print()
    print("‚ö†Ô∏è  IMPORTANTE:")
    print("   - Execute APENAS UMA VEZ para fazer a carga inicial")
    print("   - Ap√≥s concluir, use sincronizar_pluviometricos_novos.py para manter atualizado")
    print("   - O processo pode levar v√°rios minutos dependendo do volume de dados")
    print("=" * 70)
    
    # Testar conex√µes
    if not testar_conexoes():
        print("\n‚ùå Falha nos testes de conex√£o. Abortando...")
        return

    # Criar/verificar tabela
    print("\nüìã Verificando estrutura do banco de dados...")
    criar_tabela_pluviometricos()

    # Executar carga completa
    carregar_dados_completos()

if __name__ == "__main__":
    main()

